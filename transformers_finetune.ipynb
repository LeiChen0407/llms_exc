{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e288fcc-5c51-4b0b-b732-4df2a4328ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/competiton/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[4pdvGPU Msg(3056:140607572618432:libvgpu.c:869)]: Initializing.....\n",
      "[4pdvGPU Warn(3056:140607572618432:hook.c:475)]: remap handles for device 0\n",
      "[4pdvGPU Warn(3056:140607572618432:hook.c:475)]: remap handles for device 1\n",
      "[4pdvGPU Warn(3056:140607572618432:utils.c:228)]: get default cuda 2 from (null)\n",
      "[4pdvGPU Msg(3056:140607572618432:libvgpu.c:902)]: Initialized\n",
      "[4pdvGPU Msg(3056:140607572618432:memory.c:566)]: orig free=24971051008 total=25217466368 limit=25769803776 usage=236978176\n",
      "[4pdvGPU Msg(3056:140607572618432:memory.c:566)]: orig free=24971051008 total=25217466368 limit=25769803776 usage=236978176\n",
      "Loading checkpoint shards:   0%|                                                     | 0/3 [00:00<?, ?it/s][4pdvGPU Msg(3056:140607572618432:memory.c:566)]: orig free=24971051008 total=25217466368 limit=25769803776 usage=236978176\n",
      "[4pdvGPU Msg(3056:140607572618432:memory.c:566)]: orig free=24971051008 total=25217466368 limit=25769803776 usage=236978176\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████| 3/3 [01:15<00:00, 25.01s/it]\n",
      "[4pdvGPU Warn(4006:140230128813888:hook.c:475)]: remap handles for device 0\n",
      "[4pdvGPU Warn(4006:140230128813888:hook.c:475)]: remap handles for device 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "## 数据集路径\n",
    "DATA_PATH = \"./data/reformat.jsonl\"\n",
    "\n",
    "## 基础模型路径\n",
    "BASE_MODEL_NAME = \"/mnt/proj/jupyter/qwen3_4b\"\n",
    "\n",
    "## 微调模型输出路径\n",
    "OUTPUT_MODEL = \"/mnt/proj/jupyter/qwen3_4b_law\"\n",
    "OUTPUT_FINAL_MODEL = \"/mnt/proj/jupyter/qwen3_4b_merge\"\n",
    "\n",
    "# 1. 加载模型和tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f431ba-7e2d-4dba-b393-4111943e4f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████| 10877/10877 [00:09<00:00, 1207.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_function(examples):\n",
    "    texts = []\n",
    "    for instruction, input_text, output in zip(\n",
    "        examples[\"instructions\"],\n",
    "        examples[\"input\"],\n",
    "        examples[\"output\"]\n",
    "    ):\n",
    "        if input_text:\n",
    "            text = f\"Instruction: {instruction}\\nInput: {input_text}\\nResponse: {output}\"\n",
    "        else:\n",
    "            text = f\"Instruction: {instruction}\\nResponse: {output}\"\n",
    "        texts.append(text)\n",
    "    \n",
    "    # 对完整文本进行tokenize\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # 创建labels（与input_ids相同）\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized\n",
    "\n",
    "# 加载并预处理数据\n",
    "dataset = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"instructions\", \"input\", \"output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2201300c-b2c8-45f0-a600-d7da42aeaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 极简LoRA配置\n",
    "lora_target_modules = [\n",
    "    \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", # Attention 线性层\n",
    "    \"gate_proj\", \"up_proj\", \"down_proj\"     # MLP 线性层\n",
    "]\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=lora_target_modules,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    inference_mode=False\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc7deb6-85fd-470a-9f30-63c7bdacc0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4pdvGPU Warn(4527:140414721386304:hook.c:475)]: remap handles for device 0\n",
      "[4pdvGPU Warn(4527:140414721386304:hook.c:475)]: remap handles for device 1\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# 4-1 模型训练-参数准备\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_MODEL,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    # max_steps=200,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03, \n",
    "    report_to=\"none\",\n",
    "    save_total_limit=3,\n",
    "    label_names=[\"labels\"],\n",
    "    remove_unused_columns=True\n",
    ")\n",
    "\n",
    "# 4-2 模型训练-数据收集器\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# 4-3 模型训练-创建Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61b219-7bb3-4fe9-b654-24942fd43329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='355' max='680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [355/680 36:51 < 33:56, 0.16 it/s, Epoch 0.52/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.484500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.122800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.177600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.163200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.097800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4-4 模型训练-开始训练\n",
    "print(\"开始训练...\")\n",
    "trainer.train()\n",
    "\n",
    "# 5. 保存适配器\n",
    "model.save_pretrained(f\"{OUTPUT_MODEL}/adapter_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c19e0-a9ca-4843-bed6-4340de72c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer    \n",
    "from peft import PeftModel    \n",
    "import torch    \n",
    "\n",
    "BASE_MODEL_NAME = \"/home/mw/input/models4804\"    \n",
    "OUTPUT_ADAPTER_MODEL = \"/home/mw/project/output/adapter_model\"    \n",
    "OUTPUT_FINAL_MODEL = \"/home/mw/project/output/final_model\"    \n",
    "\n",
    "# 1. 加载基础模型    \n",
    "base_model = AutoModelForCausalLM.from_pretrained(    \n",
    "    BASE_MODEL_NAME,    \n",
    "    torch_dtype=torch.float16,    \n",
    "    device_map='auto',    \n",
    "    trust_remote_code=True    \n",
    ")    \n",
    "\n",
    "# 2. 加载适配器    \n",
    "peft_model = PeftModel.from_pretrained(    \n",
    "    base_model,    \n",
    "    OUTPUT_ADAPTER_MODEL    \n",
    ")    \n",
    "\n",
    "# 3. 合并模型（关键步骤）    \n",
    "merged_model = peft_model.merge_and_unload()    \n",
    "\n",
    "# 4. 保存完整模型    \n",
    "merged_model.save_pretrained(OUTPUT_FINAL_MODEL)    \n",
    "AutoTokenizer.from_pretrained(BASE_MODEL_NAME).save_pretrained(OUTPUT_FINAL_MODEL)    \n",
    "\n",
    "print('✅ 模型已合并保存到 final_pirate_model 目录')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
